{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import geom.hyperboloid as hyperboloid\n",
    "import geom.poincare as poincare\n",
    "from learning.frechet import Frechet\n",
    "from learning.pca import TangentPCA, EucPCA, PGA, HoroPCA, BSA\n",
    "from utils.data import load_graph, load_embeddings\n",
    "from utils.metrics import avg_distortion_measures, compute_metrics, format_metrics, aggregate_metrics\n",
    "from utils.sarkar import sarkar, pick_root\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s %(levelname)-8s %(message)s\",\n",
    "        level=logging.INFO,\n",
    "        datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ca-CSphd\"\n",
    "model_type = \"horopca\"\n",
    "metrics_final = [\"distortion\", \"frechet_var\"]\n",
    "dim = 10\n",
    "n_components = 2\n",
    "lr = 5e-2\n",
    "n_runs = 5\n",
    "use_sarkar = False\n",
    "sarkar_scale = 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:36:56 INFO     Running experiments for ca-CSphd dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = {}\n",
    "embeddings = {}\n",
    "logging.info(f\"Running experiments for {dataset} dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:36:59 INFO     Loaded ca-CSphd dataset with 1025 nodes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 5000x5000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(50,50))\n",
    "graph = load_graph(dataset)\n",
    "n_nodes = graph.number_of_nodes()\n",
    "nodelist = np.arange(n_nodes)\n",
    "graph_dist = torch.from_numpy(nx.floyd_warshall_numpy(graph, nodelist=nodelist))\n",
    "logging.info(f\"Loaded {dataset} dataset with {n_nodes} nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(50,50))\n",
    "# nx.draw_networkx(graph, with_labels = True, node_size=200, font_size=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:37:35 INFO     Using optimization-based embeddings\n"
     ]
    }
   ],
   "source": [
    "# get hyperbolic embeddings\n",
    "if use_sarkar:\n",
    "    # embed with Sarkar\n",
    "    logging.info(\"Using sarkar embeddings\")\n",
    "    root = pick_root(graph)\n",
    "    z = sarkar(graph, tau=sarkar_scale, root=root, dim=dim)\n",
    "    z = torch.from_numpy(z)\n",
    "    z_dist = poincare.pairwise_distance(z) / sarkar_scale\n",
    "else:\n",
    "    # load pre-trained embeddings\n",
    "    logging.info(\"Using optimization-based embeddings\")\n",
    "    assert dim in [2, 10, 50], \"pretrained embeddings are only for 2, 10 and 50 dimensions\"\n",
    "    z = load_embeddings(dataset, dim=dim)\n",
    "    z = torch.from_numpy(z)\n",
    "    z_dist = poincare.pairwise_distance(z)\n",
    "    \n",
    "# if torch.cuda.is_available():\n",
    "#     # z = z.cuda()\n",
    "#     # z_dist = z_dist.cuda()\n",
    "#     # graph_dist = graph_dist.cuda()\n",
    "#     z = z.to(\"cuda\")\n",
    "#     z_dist = z_dist.to(\"cuda\")\n",
    "#     graph_dist = graph_dist.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:37:35 INFO     Embedding distortion in 10 dimensions: 0.1441\n"
     ]
    }
   ],
   "source": [
    "# compute embeddings' distortion\n",
    "distortion = avg_distortion_measures(graph_dist, z_dist)[0]\n",
    "logging.info(\"Embedding distortion in {} dimensions: {:.4f}\".format(dim, distortion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:37:36 INFO     Computing the Frechet mean to center the embeddings\n",
      "2024-01-11 09:37:36 INFO     Mean computation has converged: True\n"
     ]
    }
   ],
   "source": [
    "# Compute the mean and center the data\n",
    "logging.info(\"Computing the Frechet mean to center the embeddings\")\n",
    "frechet = Frechet(lr=1e-2, eps=1e-5, max_steps=5000)\n",
    "mu_ref, has_converged = frechet.mean(z, return_converged=True)\n",
    "logging.info(f\"Mean computation has converged: {has_converged}\")\n",
    "x = poincare.reflect_at_zero(z, mu_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 09:43:29 INFO     Running horopca for dimensionality reduction\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Running {model_type} for dimensionality reduction\")\n",
    "metrics = []\n",
    "dist_orig = poincare.pairwise_distance(x)\n",
    "\n",
    "\n",
    "def run(dataset=\"smalltree\", \n",
    "        model_type=\"horopca\",\n",
    "        metrics_final=[\"distortion\", \"frechet_var\"],\n",
    "        dim=10,\n",
    "        n_components=2, \n",
    "        n_runs=5,\n",
    "        use_sarkar=False,\n",
    "        sarkar_scale=3.5, lr=5e-2):\n",
    "    \n",
    "    pca_models = {\n",
    "        'pca': {'class': EucPCA, 'optim': False, 'iterative': False, \"n_runs\": 1},\n",
    "        'tpca': {'class': TangentPCA, 'optim': False, 'iterative': False, \"n_runs\": 1},\n",
    "        'pga': {'class': PGA, 'optim': True, 'iterative': True, \"n_runs\": n_runs},\n",
    "        'bsa': {'class': BSA, 'optim': True, 'iterative': False, \"n_runs\": n_runs},\n",
    "        'horopca': {'class': HoroPCA, 'optim': True, 'iterative': False, \"n_runs\": n_runs},\n",
    "    }\n",
    "    if model_type in pca_models.keys():\n",
    "        model_params = pca_models[model_type]\n",
    "        for _ in range(model_params[\"n_runs\"]):\n",
    "            model = model_params['class'](dim=dim, n_components=n_components, lr=lr, max_steps=500)\n",
    "            # if torch.cuda.is_available():\n",
    "            #     model.cuda()\n",
    "            model.fit(x, iterative=model_params['iterative'], optim=model_params['optim'])\n",
    "            metrics.append(model.compute_metrics(x))\n",
    "            embeddings = model.map_to_ball(x).detach().cpu().numpy()\n",
    "        metrics = aggregate_metrics(metrics)\n",
    "    else:\n",
    "        # run hMDS baseline\n",
    "        logging.info(f\"Running hMDS\")\n",
    "        x_hyperboloid = hyperboloid.from_poincare(x)\n",
    "        distances = hyperboloid.distance(x.unsqueeze(-2), x.unsqueeze(-3))\n",
    "        D_p = poincare.pairwise_distance(x)\n",
    "        x_h = hyperboloid.mds(D_p, d=n_components)\n",
    "        x_proj = hyperboloid.to_poincare(x_h)\n",
    "        embeddings[\"hMDS\"] = x_proj.numpy()\n",
    "        metrics = compute_metrics(x, x_proj)\n",
    "\n",
    "    logging.info(f\"Experiments for {dataset} dataset completed.\")\n",
    "    logging.info(\"Computing evaluation metrics\")\n",
    "    results = format_metrics(metrics, metrics_final)\n",
    "    for line in results:\n",
    "        logging.info(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(dataset, model_type, metrics_final, dim, n_components, n_runs, use_sarkar, sarkar_scale, lr)\u001b[0m\n\u001b[1;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m model_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m](dim\u001b[38;5;241m=\u001b[39mdim, n_components\u001b[38;5;241m=\u001b[39mn_components, lr\u001b[38;5;241m=\u001b[39mlr, max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# if torch.cuda.is_available():\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     model.cuda()\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miterative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m metrics\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mcompute_metrics(x))\n\u001b[1;32m     30\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mmap_to_ball(x)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Works/github/MML-HoroPCA/learning/pca.py:167\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, x, iterative, optim)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Finds principal components using optimization or spectral decomposition approaches.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    optim: boolean (true to find components via optimization, defaults to SVD otherwise)\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_optim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterative\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_spectral(x)\n",
      "File \u001b[0;32m~/Works/github/MML-HoroPCA/learning/pca.py:131\u001b[0m, in \u001b[0;36mPCA.fit_optim\u001b[0;34m(self, x, iterative)\u001b[0m\n\u001b[1;32m    129\u001b[0m loss_vals\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m    130\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 131\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1e5\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# if self.components[0].grad.sum().isnan().item():\u001b[39;00m\n",
      "File \u001b[0;32m~/Works/github/MML-HoroPCA/.venv/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Works/github/MML-HoroPCA/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
